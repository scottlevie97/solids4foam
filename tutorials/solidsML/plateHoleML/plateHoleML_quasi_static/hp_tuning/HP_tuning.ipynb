{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 13:28:57.843782: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 13:28:58.502571: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-06 13:28:58.834280: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-06 13:28:58.834314: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 13:28:59.076015: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-06 13:29:01.621657: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 13:29:01.622532: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 13:29:01.622563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def inputsoutputsAllfiles(trainIterations, filepatharray, Timestepsize, maxtimestep):\n",
    "\n",
    "    def xyz(iteration, filepath, Timestepsize, Timestep):\n",
    "\n",
    "        Time = Timestep*Timestepsize \n",
    "        if Time%1 == 0:\n",
    "            Time =int(Time)\n",
    "        else: \n",
    "            Time = round(Time,2)\n",
    "        my_file = open(filepath + str(Time) +\"/solidsCellD_iteration\"+str(iteration))\n",
    "        string_list = my_file.readlines()\n",
    "        index=18\n",
    "        string_list = string_list[index+2:len(string_list)] \n",
    "        string_list = string_list[0:len(string_list)-4] \n",
    "        i=0\n",
    "        for i in range(len(string_list)):\n",
    "            string_list[i]=string_list[i].replace(\"(\",\"\")\n",
    "            string_list[i]=string_list[i].replace(\")\",\"\")\n",
    "            string_list[i]=string_list[i].split()\n",
    "        arr=np.array(string_list)\n",
    "        arr= arr.astype(np.float64)\n",
    "        x = arr[:,0]\n",
    "        y = arr[:, 1]\n",
    "        z = arr[:, 2]\n",
    "\n",
    "        return x, y, z #, arr\n",
    "        \n",
    "      \n",
    "    def maxIteration (Timestep, Timestepsize, filepath):\n",
    "        Time = Timestep*Timestepsize\n",
    "        Time = round(Time,2)   # Rounds to deicimal place\n",
    "        file = filepath + \"residual.dat\"\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df.columns = ['One'] #Labels first Column\n",
    "\n",
    "        df['One'] = df['One'].astype('string') # Converts to string\n",
    "\n",
    "        new = df['One'].str.split(' ', expand = True) #splits into new dataframe on spaces\n",
    "\n",
    "        df['TimeStep']= new[0].astype('float')  # labels new columns and inserts in dataframe\n",
    "        df['solverPerfInitRes']= new[1].astype('float')  # labels new columns and inserts in dataframe\n",
    "        df['residualvf']= new[2].astype('float')  # labels new columns and inserts in dataframe\n",
    "        df['materialResidual']= new[3].astype('float')  # labels new columns and inserts in dataframe\n",
    "        df[\"IterationNumber\"]= new[4].astype('float') # labels new columns and inserts in dataframe\n",
    "\n",
    "        df.drop(columns =['One'], inplace = True) #Removes original column\n",
    "\n",
    "        array = np.array\n",
    "        array = []\n",
    "\n",
    "        for i in range(len(df)):        #loops through residual file\n",
    "            if df['TimeStep'][i] == Time:   # Finds values for a timestep\n",
    "                x = df['IterationNumber'][i]\n",
    "                array.append(x)            # Creates arrays of iteration numbers\n",
    "                \n",
    "        max = np.max(array) # returns max of array\n",
    "        max=int(max)\n",
    "        return max\n",
    "    \n",
    "    def inputsoutputsAllTimesteps(trainIterations, filepath, Timestepsize):\n",
    "\n",
    "        def inputsoutputsTimestep(trainIterations, filepath, Timestepsize, Timestep):\n",
    "\n",
    "            max = maxIteration(Timestep, Timestepsize, filepath)\n",
    "\n",
    "            x,y,z = xyz(1, filepath, Timestepsize, Timestep)\n",
    "            matrix = np.array(np.vstack((x,y,z))) #Gives matrix a starting value which is removed later\n",
    "\n",
    "            for i in range(0,trainIterations): # loops for each iteration up to trainIteration\n",
    "                x,y,z = xyz(i,filepath, Timestepsize, Timestep)\n",
    "                arr = np.vstack((x,y,z))  # gives array with x, y, z values for each iteration\n",
    "                matrix = np.concatenate((matrix, arr))   # combines arrays\n",
    "\n",
    "            inputs = matrix[3:,:] # removes initial value\n",
    "\n",
    "            xmax, ymax, zmax = xyz(max, filepath, Timestepsize, Timestep)\n",
    "            outputs = np.vstack((xmax,ymax,zmax)) # array of values at max iteration\n",
    "\n",
    "            inputs = np.transpose(inputs)  # multiple columns : (x1, y1, z1, x2, y2, z2 ...)\n",
    "            outputs = np.transpose(outputs)\n",
    "\n",
    "            return inputs, outputs\n",
    "\n",
    "        arrinputs = np.ones((1, trainIterations*3)) # first row to be removed after\n",
    "        arroutputs = np.ones((1, 3))\n",
    "\n",
    "        #combines inputs and outputs of all timesteps\n",
    "\n",
    "        for Timestep in range(1,maxtimestep+1):\n",
    "            inputs, outputs = inputsoutputsTimestep(trainIterations, filepath, Timestepsize, Timestep)\n",
    "            arrinputs = np.vstack((arrinputs,inputs))\n",
    "            arroutputs = np.vstack((arroutputs,outputs))\n",
    "\n",
    "        arrinputs = arrinputs[1:,:] #removes oriinal row of ones\n",
    "        arroutputs = arroutputs[1:,:]#removes oriinal row of ones\n",
    "\n",
    "        outputs = arroutputs\n",
    "        inputs = arrinputs\n",
    "\n",
    "        return inputs, outputs   # Returns the inputs and outputs of All timesteps for one file\n",
    "\n",
    "    arrinputs = np.ones((1, trainIterations*3))\n",
    "    arroutputs = np.ones((1, 3))\n",
    "\n",
    "    for i in range(0,len(filepatharray),1):\n",
    "        inputs, outputs = inputsoutputsAllTimesteps(trainIterations, filepatharray[i], Timestepsize)\n",
    "        arrinputs = np.vstack((arrinputs,inputs))\n",
    "        arroutputs = np.vstack((arroutputs,outputs))\n",
    "\n",
    "    arrinputs = arrinputs[1:,:] #removes oriinal row of ones\n",
    "    arroutputs = arroutputs[1:,:]#removes oriinal row of ones\n",
    "\n",
    "    outputs = arroutputs\n",
    "    inputs = arrinputs\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = \"../mesh10/plateHole/\"\n",
    "\n",
    "filepatharray = [filepath1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainIterations = input(\"Enter your training iteration value: \")\n",
    "trainIterations = 20\n",
    "\n",
    "Timestepsize = 1\n",
    "maxtimestep = 1\n",
    "\n",
    "inputs, outputs = inputsoutputsAllfiles(trainIterations, filepatharray, Timestepsize, maxtimestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "X = inputs\n",
    "y = outputs\n",
    "\n",
    "scalerI = StandardScaler().fit(X) #FitScaler\n",
    "scalerO = StandardScaler().fit(y)\n",
    "\n",
    "\n",
    "scaledX = scalerI.transform(X) # Scale X\n",
    "scaledY = scalerO.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41af2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for number of epocs\n",
    "\n",
    "# answer_epochs = input(\"Number of epochs?: \")\n",
    "# answer_epochs = int(answer_epochs)\n",
    "\n",
    "answer_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask if solidProperties is ready\n",
    "\n",
    "# answer_solidsProp = input(\"Is solidProperties ready?: (y/n)\")\n",
    "\n",
    "answer_solidsProp = \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask to train or load model\n",
    "\n",
    "# answer_trainOrLoadModel = input(\"Train or load model?: (t/l) \")\n",
    "\n",
    "answer_trainOrLoadModel = \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([100, 200, 300]))\n",
    "HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([100, 150, 200]))\n",
    "HP_NUM_UNITS_3 = hp.HParam('num_units_3', hp.Discrete([25, 50, 75]))\n",
    "\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS_1, HP_NUM_UNITS_2, HP_NUM_UNITS_3, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44466424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(hparams[HP_NUM_UNITS_1], input_dim=len(X[0,:]), \n",
    "    activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dense(hparams[HP_NUM_UNITS_2], \n",
    "    activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dense(hparams[HP_NUM_UNITS_3], \n",
    "    activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dense(3))\n",
    "\n",
    "  # model = tf.keras.models.Sequential([\n",
    "  #   tf.keras.layers.Flatten(),\n",
    "  #   tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "  #   tf.keras.layers.Dense(3),\n",
    "  # ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='mean_squared_error',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  log_dir = \"logs/fit/\" \n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "  history = model.fit(scaledX, scaledY, epochs=answer_epochs, verbose=1)\n",
    "  accuracy = model.evaluate(scaledX, scaledY, verbose=0)\n",
    "  return accuracy\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    # tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594c4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units_1': 50, 'num_units_2': 10, 'optimizer': 'adam'}\n",
      "Epoch 1/1000\n",
      "313/313 [==============================] - 0s 604us/step - loss: 0.0538 - accuracy: 0.9406\n",
      "Epoch 2/1000\n",
      "313/313 [==============================] - 0s 582us/step - loss: 5.4588e-04 - accuracy: 0.9882\n",
      "Epoch 3/1000\n",
      "313/313 [==============================] - 0s 611us/step - loss: 4.1438e-04 - accuracy: 0.9895\n",
      "Epoch 4/1000\n",
      "313/313 [==============================] - 0s 595us/step - loss: 3.5562e-04 - accuracy: 0.9903\n",
      "Epoch 5/1000\n",
      "313/313 [==============================] - 0s 590us/step - loss: 3.7187e-04 - accuracy: 0.9910\n",
      "Epoch 6/1000\n",
      "313/313 [==============================] - 0s 625us/step - loss: 3.2788e-04 - accuracy: 0.9913\n",
      "Epoch 7/1000\n",
      "313/313 [==============================] - 0s 567us/step - loss: 2.5872e-04 - accuracy: 0.9915\n",
      "Epoch 8/1000\n",
      "313/313 [==============================] - 0s 531us/step - loss: 2.3119e-04 - accuracy: 0.9919\n",
      "Epoch 9/1000\n",
      "313/313 [==============================] - 0s 601us/step - loss: 2.0634e-04 - accuracy: 0.9928\n",
      "Epoch 10/1000\n",
      "313/313 [==============================] - 0s 632us/step - loss: 2.7875e-04 - accuracy: 0.9926\n",
      "Epoch 11/1000\n",
      "313/313 [==============================] - 0s 635us/step - loss: 1.8479e-04 - accuracy: 0.9943\n",
      "Epoch 12/1000\n",
      "313/313 [==============================] - 0s 595us/step - loss: 1.7403e-04 - accuracy: 0.9939\n",
      "Epoch 13/1000\n",
      "313/313 [==============================] - 0s 649us/step - loss: 1.9962e-04 - accuracy: 0.9942\n",
      "Epoch 14/1000\n",
      "313/313 [==============================] - 0s 608us/step - loss: 1.5375e-04 - accuracy: 0.9944\n",
      "Epoch 15/1000\n",
      "313/313 [==============================] - 0s 587us/step - loss: 1.8530e-04 - accuracy: 0.9947\n",
      "Epoch 16/1000\n",
      "313/313 [==============================] - 0s 576us/step - loss: 1.3344e-04 - accuracy: 0.9946\n",
      "Epoch 17/1000\n",
      " 86/313 [=======>......................] - ETA: 0s - loss: 1.0968e-04 - accuracy: 0.9938"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_517784/179513717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- Starting trial: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/hparam_tuning/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0msession_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_517784/3949333833.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_dir, hparams)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# record the values used in this trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_517784/3949333833.py\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaledX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaledY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaledX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaledY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/python3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!rm -r logs\n",
    "\n",
    "session_num = 0\n",
    "\n",
    "for num_units_1 in HP_NUM_UNITS_1.domain.values:\n",
    "    for num_units_2 in HP_NUM_UNITS_2.domain.values:\n",
    "        for num_units_3 in HP_NUM_UNITS_3.domain.values:\n",
    "                for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS_1: num_units_1,\n",
    "                        HP_NUM_UNITS_2: num_units_2,\n",
    "                        HP_NUM_UNITS_3: num_units_3,\n",
    "                        HP_OPTIMIZER: optimizer,\n",
    "                    }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    print('--- Starting trial: %s' % run_name)\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    run('logs/hparam_tuning/' + run_name, hparams)\n",
    "                    session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9aabfd538fa8049b1f044693c78d5a10e8e59fb069c700b4785242fc819fb12a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
